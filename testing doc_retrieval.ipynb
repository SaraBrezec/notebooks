{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from modules.library import documentRetrieval as dr\n",
    "from modules.library.postgresql import PostgresQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gas']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"gas\"\n",
    "tokens= query.split() #change latere to QE\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg = PostgresQL() \n",
    "pg.connect(database=\"envirolens\", user=\"postgres\", password=\"dbpass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_query(query_words):\n",
    "    \"\"\" From database returns list of dictionaries containing document IDs and text. Documents contain at least one query word.\n",
    "    Args:\n",
    "        query_words(list): List of query words\n",
    "    Returns: \n",
    "        documents(list): list of dictionaries containing document IDs and text\"\"\"\n",
    "    output = '|'.join(query_words)\n",
    "    SQL = \"\"\"\n",
    "            SELECT document_id, fulltext_cleaned FROM documents\n",
    "            WHERE to_tsvector('english', fulltext_cleaned) @@ to_tsquery('english',\"\"\" + '\\''+ output + '\\'' + \"\"\");\"\"\"\n",
    "    documents = pg.execute(SQL)\n",
    "    return(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5493"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens = request\n",
    "\n",
    "docs = db_query(tokens)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_nb_docs():\n",
    "    SQL = \"\"\"\n",
    "            SELECT COUNT(*) FROM documents;\"\"\"\n",
    "    leng = pg.execute(SQL)\n",
    "    leng = leng[0].get('count')\n",
    "    return(leng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321488"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = db_nb_docs()\n",
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_dict_structure(dict_list):\n",
    "    \"\"\"Takes list of dicts from db_query and changes to dict with key=id, value = text (used for metrices).\n",
    "    Args:\n",
    "        dict_list (list): List of dictionaries from db_query.\n",
    "    Returns:\n",
    "        texts (dictionary): Dictionary with document IDs as keys and document text as values.\n",
    "    \"\"\"\n",
    "    texts = {}\n",
    "    for dict in dict_list:\n",
    "        doc_id = dict.get('document_id')\n",
    "        text = dict.get('fulltext_cleaned')\n",
    "        texts.update({doc_id: text})\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5493"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = change_dict_structure(docs) \n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(token, token_list, wv ):\n",
    "    \"\"\"Calculates similarity between token and list of tokens.\n",
    "    Args:\n",
    "        token (str): String for wich we are calculating similarity.\n",
    "        token_list (list): List of tokens to which we are calculating similarity.\n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        avreage_similarity (float): Number that signifes the similarity of token to token_list words.\n",
    "    \"\"\"\n",
    "\n",
    "    similarity = 0\n",
    "    num_of_tokens = 0\n",
    "    for toks in token_list:\n",
    "        # check if the token is in the vocabulary\n",
    "\n",
    "        if toks in wv.vocab.keys():\n",
    "            num_of_tokens += 1\n",
    "            similarity += wv.similarity(toks, token) \n",
    "            avreage_similarity = similarity/num_of_tokens\n",
    "    return avreage_similarity\n",
    "\n",
    "\n",
    "def probability_multiply(probability, token_frequency, n):\n",
    "    \"\"\"Assigns score to document based on multiplication of probabilities. Probability is token frequency devided by length of document.\n",
    "       In this metric only documents containing all query words have positive probability.\n",
    "       Args:\n",
    "           probability (float): Previously calculated probability.\n",
    "           token_frequency (float):  Number of appearances of token in text.\n",
    "           n (int): Length of text.\n",
    "       Returns:\n",
    "           probability_value (float): New caclculated probability.\n",
    "    \"\"\"\n",
    "    probability_value = probability*(token_frequency/n)\n",
    "    return probability_value\n",
    "\n",
    "def probability_sum(probability, token_frequency, n):\n",
    "    \"\"\"Assigns score to document based on summation of probabilities.\n",
    "    Args:\n",
    "        probability (float): Previously calculated probability.\n",
    "        token_frequency (float):  Number of appearances of token in text.\n",
    "        n (int): Length of text.\n",
    "    Returns:\n",
    "        probability_value (float): New caclculated probability.\n",
    "    \"\"\"\n",
    "    probability_value = probability+(token_frequency/n) \n",
    "    return probability_value\n",
    "\n",
    "def word_value(word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"values word based on whether is in original token set or expanded, if alpha -1 value equals to cosine similarity\n",
    "    Args:\n",
    "        word (string): Word or token for which we are calculating value.\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                        Usually between 0.5 (all words are treated equal) and 1 (expansion words have value 0). \n",
    "                        For alpha -1 values equal to cosine similarity to query words.\n",
    "        original_tokens(list): List of strings. Tokenized original query. Usually also extension (extension by summation of 2 consecutive words).\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        value (float): Value of the word based on whether is in original token set or expanded set.\n",
    "    \"\"\"\n",
    "    only_expanded = []\n",
    "    for token in top_expansion:\n",
    "        if token not in original_tokens:\n",
    "            only_expanded.append(token)       \n",
    "    sum_similarity = 0\n",
    "    for exp_token in only_expanded:\n",
    "            sum_similarity += similarity(exp_token,original_tokens, wv)        \n",
    "    if alpha == -1:\n",
    "        if word in original_tokens:\n",
    "            value = 1\n",
    "        else:\n",
    "            value = similarity(word, original_tokens, wv)/sum_similarity\n",
    "    else:\n",
    "        if word in original_tokens:\n",
    "            value = alpha\n",
    "        else:\n",
    "            value = (1-alpha)*similarity(word, original_tokens, wv)/sum_similarity\n",
    "    return value\n",
    "\n",
    "def probability_sum_weight(probability, token_frequency, n, word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"Assigns weighted score to document based on summation of probabilities.\n",
    "        Args:\n",
    "        probability (float): Previously calculated probability.\n",
    "        token_frequency (float):  Number of appearances of token in text.\n",
    "        n (int): Length of text.\n",
    "        word (string): Word or token for which we are calculating value.\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                        Usually between 0.5 (all words are treated equal) and 1 (expansion words have value 0). \n",
    "                        For alpha -1 values equal to cosine similarity to query words.\n",
    "        original_tokens(list): List of strings. Tokenized original query. Usually also extension (extension by summation of 2 consecutive words)\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        probability_value (float): New caclculated probability.\n",
    "    \"\"\"\n",
    "    probability_value = probability+(token_frequency/n)*word_value(word, alpha, original_tokens, top_expansion, wv)\n",
    "    return probability_value\n",
    "\n",
    "def top_positives(dictionary,n):\n",
    "    \"\"\"Takes dict and returns first n tuples of key,values sorted by values descending, returns only items with positive values.\n",
    "    Args:\n",
    "        dictionary (dict): Dictionary we want to sort by values.\n",
    "        n (int): Number of returned items. If there are less than n items in dictonary or less than n items with positive values,\n",
    "                 returns all items (with positive valuses) sorted.\n",
    "    Returns:\n",
    "        sorted_positives_top (list): List of n tuples. If there are less than n items in dictonary or less than n items with \n",
    "                                     positive values, returns all items (with positive valuses) sorted.\n",
    "    \"\"\"\n",
    "    positives = {} \n",
    "    for k,v in dictionary.items():\n",
    "        if v > 0:\n",
    "            positives.update({k: v})\n",
    "    sorted_positives = sorted(positives.items(), key=lambda x: x[1],reverse=True)\n",
    "    if len(sorted_positives) > n:\n",
    "        sorted_positives_top = sorted_positives[0:n]\n",
    "    else:\n",
    "        sorted_positives_top = sorted_positives\n",
    "    return sorted_positives_top\n",
    "\n",
    "def probability_score(tokens,texts, probability_function,m, *args):\n",
    "    # final function, takes also probability_function probability_sum_weight, but doesnt give final result (used in probability_score_sum_weights)\n",
    "    \"\"\"Assigns score to documents based on probability_function metric.\n",
    "    Args:\n",
    "        tokens (list): List of tokens (tokenized query). If needed also extension (extension by summation of 2 consecutive words).\n",
    "        texts (dict):  Keys represent document ids, values are document text. \n",
    "        probability_function (function): Metric function that calculates document relavance. Functions: probability_multiply, probability_sum. Require only first 4 arguments.\n",
    "        m (int): Number of returned tuples (positive scores), sorted by highest scores. If m=o returns all.\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                       For alpha 0.5 all words have same weights (but not same values!), for alpha 1 expansion words have value 0. \n",
    "                       For alpha -1 values equal to cosine similarity to query words. \n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        document_probability (list): Tuples of document ids and scores that measure document relavance. Returns n tuples with highest score.\n",
    "    \"\"\"\n",
    "\n",
    "    #args[0] == top_expansion\n",
    "    #args[1] == alpha\n",
    "    #args[2] == wv\n",
    "\n",
    "    break_loop = False\n",
    "    document_probability = {}\n",
    "    for k, v in texts.items():\n",
    "        n = len(v)\n",
    "        if probability_function == probability_multiply:\n",
    "            probability = 1\n",
    "        else:\n",
    "            probability = 0\n",
    "        if probability_function == probability_sum_weight:\n",
    "            if len(args) == 3:\n",
    "                for i in range(len(tokens)):\n",
    "                    token_frequency = v.count(tokens[i])\n",
    "                    probability = probability_sum_weight(probability, token_frequency, n,tokens[i], args[1], tokens, args[0], args[2])\n",
    "                document_probability.update({k: probability})\n",
    "            else:\n",
    "                print(\"Error, number of arguments does not match.\")\n",
    "                break_loop = True\n",
    "                break \n",
    "        elif break_loop:\n",
    "            break\n",
    "        elif probability_function == probability_sum or probability_function == probability_multiply:\n",
    "            if len(args) == 0:\n",
    "                for i in range(len(tokens)):\n",
    "                    token_frequency = v.count(tokens[i])\n",
    "                    probability = probability_function(probability, token_frequency, n)\n",
    "                document_probability.update({k: probability})\n",
    "            else:\n",
    "                print(\"Error, number of arguments does not match.\")\n",
    "                break_loop = True\n",
    "                break \n",
    "        elif break_loop:\n",
    "            break\n",
    "        else:\n",
    "            print(\"Error, metric function not defined.\")\n",
    "     \n",
    "    if m == 0:\n",
    "        return [(k, v) for k, v in document_probability.items()] \n",
    "    else:      \n",
    "        document_probability = top_positives(document_probability,m)        \n",
    "        return document_probability\n",
    "\n",
    "def probability_score_sum_weights(original_tokens, top_expansion, texts,m, alpha, wv): \n",
    "    # final fuction\n",
    "    \"\"\"As probability_score only weighted.\n",
    "        Args:\n",
    "        original_tokens(list): List of strings. Tokenized original query. Usually also extension (extension by summation of 2 consecutive words)\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        texts (dict):  Keys represent document ids, values are document text.\n",
    "        m (int): Number of returned tuples (positive scores), sorted by highest scores. If m=o returns all.\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                       For alpha 0.5 all words have same weights (but not same values!), for alpha 1 expansion words have value 0. \n",
    "                       For alpha -1 values equal to cosine similarity to query words. \n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        document_score (list): Tuples of document ids and scores that measure document relavance. Returns n tuples with highest score.\n",
    "    \"\"\"\n",
    "    tokens = original_tokens+top_expansion\n",
    "    document_score = probability_score(tokens,texts, probability_sum_weight,m, top_expansion, alpha, wv)\n",
    "    return document_score\n",
    "\n",
    "def number_documents_tokens_appear(tokens,texts):\n",
    "    \"\"\"For each token in tokens counts the number of documents in which token has appeared.\n",
    "        Args:\n",
    "        tokens (list): List of tokens.\n",
    "        texts (dict):  Keys represent document ids, values are document text.\n",
    "    Returns:\n",
    "        documents_per_token (list): List of numbers that count number of documnets in which certain token appears.\n",
    "                                    Index of element in tokens list is the same as index in documents_per_token list for that element value.\n",
    "    \"\"\"\n",
    "    documents_per_token = []\n",
    "    for i in range(len(tokens)):\n",
    "        documents_per_token.append(0)\n",
    "    for text in texts.values():\n",
    "        for i in range(len(tokens)):\n",
    "            token = tokens[i]\n",
    "            if token in text:\n",
    "                documents_per_token[i] = documents_per_token[i]+1\n",
    "    return documents_per_token\n",
    "\n",
    "def tfidf_sum(probability,  token_frequency, n, idf):\n",
    "    \"\"\"Assigns score to document based on TF-IDF metric.\n",
    "    Args:\n",
    "        probability (float): Previously calculated tfidf score.\n",
    "        token_frequency (float):  Number of appearances of token in text.\n",
    "        n (int): Length of text.\n",
    "        idf (float): Idf of token.\n",
    "    Returns:\n",
    "        tfidf_value (float): New caclculated tfidf score.\n",
    "    \"\"\"\n",
    "\n",
    "    tfidf_value = probability+((token_frequency/n)*idf)\n",
    "    return tfidf_value\n",
    "\n",
    "def tfidf_sum_weight(probability,  token_frequency, n, idf, word, alpha, original_tokens, top_expansion, wv):\n",
    "    \"\"\"Assigns weighted score to document based on TF-IDF metric.\n",
    "    Args:\n",
    "        probability (float): Previously calculated tfidf score.\n",
    "        token_frequency (float):  Number of appearances of token in text.\n",
    "        n (int): Length of text.\n",
    "        idf (float): Idf of token.\n",
    "        word (string): Word or token for which we are calculating value.\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                        Usually between 0.5 (all words are treated equal) and 1 (expansion words have value 0). \n",
    "                        For alpha -1 values equal to cosine similarity to query words.\n",
    "        original_tokens(list): List of strings. Tokenized original query. Usually also extension (extension by summation of 2 consecutive words)\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        tfidf_value (float): New caclculated tfidf score.\n",
    "    \"\"\"\n",
    "    tfidf_value = probability+((token_frequency/n)*idf)*word_value( word, alpha, original_tokens, top_expansion, wv)\n",
    "    return tfidf_value\n",
    "\n",
    "\n",
    "def tfidf_score_str(tokens,texts,tfidf_function_name,m = 10,*args):\n",
    "    \"\"\"Takes function name as input, returns function\"\"\"\n",
    "    if tfidf_function_name == 'tfidf_sum':\n",
    "            return tfidf_score(tokens,texts,tfidf_sum,m)\n",
    "    else:\n",
    "        raise Exception(\"Error, different function name\")\n",
    "\n",
    "def tfidf_score(tokens, texts, tfidf_function,nb_all_texts_in_db,m = 10, *args):\n",
    "    #final function\n",
    "    \"\"\"Assigns score to documents based on tfidf_function metric.\n",
    "    Args:\n",
    "        tokens (list): List of tokens (tokenized query). If needed also extension (extension by summation of 2 consecutive words).\n",
    "        texts (dict):  Keys represent document ids, values are document text. \n",
    "        probability_function (function): Metric function that calculates document relavance. Functions: tfidf_sum; require only first 4 arguments, tfidf_sum_weight; require all arguments.\n",
    "        m (int): Number of returned tuples (positive scores), sorted by highest scores. If m=o returns all.\n",
    "        top_expansion (list): List of expanded words. Usually candidates (kNN expansion).\n",
    "        alpha (float): Number between 0 and 1. Weight that emphasizes the difference between original query words and expansions. \n",
    "                       For alpha 0.5 all words have same weights (but not same values!), for alpha 1 expansion words have value 0. \n",
    "                       For alpha -1 values equal to cosine similarity to query words. \n",
    "        wv (Word2VecKeyedVectors): Word embeddings.\n",
    "    Returns:\n",
    "        document_probability (list): Tuples of document ids and scores that measure document relavance. Returns n tuples with highest score.\n",
    "        not_appear (list): List of words that did not occure in any document.\n",
    "    \"\"\"\n",
    "    #args[0] == top_expansion\n",
    "    #args[1] == alpha\n",
    "    #args[2] == wv\n",
    "\n",
    "    break_loop = False\n",
    "    if len(args):\n",
    "        tokens_together = tokens+args[0]\n",
    "    else:\n",
    "        #print(\"y\")\n",
    "        tokens_together = tokens\n",
    "    nb_docs_tokens_appeared = number_documents_tokens_appear(tokens_together,texts)\n",
    "    #print(len(nb_docs_tokens_appeared))\n",
    "    filtered_nb_docs_tokens_appeared = [elt for elt in nb_docs_tokens_appeared if not elt == 0]\n",
    "    #print((filtered_nb_docs_tokens_appeared))\n",
    "    not_appear = []\n",
    "    appear = []\n",
    "\n",
    "    for i in range(len(nb_docs_tokens_appeared)):\n",
    "\n",
    "        if nb_docs_tokens_appeared[i] == 0:\n",
    "            not_appear.append(tokens_together[i])\n",
    "        else:\n",
    "            appear.append(tokens_together[i])    \n",
    "    l = nb_all_texts_in_db #\n",
    "\n",
    "    document_probability = {}\n",
    "    for k, v in texts.items():\n",
    "\n",
    "        n = len(v)\n",
    "        probability = 0\n",
    "        for i in range(len(appear)):\n",
    "            token_frequency = v.count(appear[i])\n",
    "            idf = math.log(l/filtered_nb_docs_tokens_appeared[i])\n",
    "            if tfidf_function == tfidf_sum:\n",
    "                if len(args) == 0:\n",
    "                   # print(\"a\")\n",
    "                   \n",
    "                    probability = tfidf_sum(probability,  token_frequency, n, idf)\n",
    "                else:\n",
    "                    print(\"Error, number of arguments does not match\")\n",
    "                    break_loop = True\n",
    "                    break \n",
    "            elif tfidf_function == tfidf_sum_weight:\n",
    "                if len(args) == 3:\n",
    "                    probability = tfidf_sum_weight(probability,  token_frequency, n, idf,appear[i], args[1], tokens, args[0], args[2])\n",
    "                else:\n",
    "                    print(\"Error, number of arguments does not match\")\n",
    "                    break_loop = True\n",
    "\n",
    "                    break \n",
    "        if break_loop:\n",
    "            break\n",
    "        document_probability.update({k: probability})\n",
    "    #print((document_probability))    \n",
    "    if m == 0:\n",
    "        return [(k, v) for k, v in document_probability.items()] \n",
    "    else:      \n",
    "        document_probability = top_positives(document_probability,m)        \n",
    "        #print(len(document_probability))\n",
    "        return document_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_score = tfidf_score_str(tokens,texts,'tfidf_sum',length,10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-2e66da8d1ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tokens = request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdb_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_dict_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtfidf_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_score_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tfidf_sum'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "metadata = db.db_return_docs_metadata(tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
